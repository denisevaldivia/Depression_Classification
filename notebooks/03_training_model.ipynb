{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5230de6c",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2\" width=\"240px\" height=\"180px\" />\n",
    "\n",
    "# <font color= #bbc28d> **Clasificación de Depresión - Modelado** </font>\n",
    "#### <font color= #2E9AFE> `Proyecto de Ciencia de Datos`</font>\n",
    "- <Strong> Sofía Maldonado, Diana Valdivia, Samantha Sánchez & Vivienne Toledo </Strong>\n",
    "- <Strong> Fecha </Strong>: 11/11/2025.\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Image retrieved from: https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2/p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bd9446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Databricks Env\n",
    "import pathlib\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Optimization\n",
    "import math\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7b739",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **Credenciales & Set-up inicial** </font>\n",
    "Para poder trabajar con MLFlow es necesario ingresar con nuestros tokens de acceso y definir la base con la que estaremos trabajando, en nuestro caso será con Databricks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36e595",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 16:22:37 INFO mlflow.tracking.fluent: Experiment with name '/Users/pipochatgpt@gmail.com/depression-project' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "ename": "RestException",
     "evalue": "RESOURCE_DOES_NOT_EXIST: Parent directory /Users/pipochatgpt@gmail.com does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRestException\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      7\u001b[39m EXPERIMENT_NAME = \u001b[33m\"\u001b[39m\u001b[33m/Users/pipochatgpt@gmail.com/depression-project\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      9\u001b[39m mlflow.set_tracking_uri(\u001b[33m\"\u001b[39m\u001b[33mdatabricks\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m experiment = \u001b[43mmlflow\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEXPERIMENT_NAME\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:194\u001b[39m, in \u001b[36mset_experiment\u001b[39m\u001b[34m(experiment_name, experiment_id)\u001b[39m\n\u001b[32m    189\u001b[39m _logger.info(\n\u001b[32m    190\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mExperiment with name \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m does not exist. Creating a new experiment.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    191\u001b[39m     experiment_name,\n\u001b[32m    192\u001b[39m )\n\u001b[32m    193\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m194\u001b[39m     experiment_id = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m MlflowException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m e.error_code == \u001b[33m\"\u001b[39m\u001b[33mRESOURCE_ALREADY_EXISTS\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    197\u001b[39m         \u001b[38;5;66;03m# NB: If two simultaneous processes attempt to set the same experiment\u001b[39;00m\n\u001b[32m    198\u001b[39m         \u001b[38;5;66;03m# simultaneously, a race condition may be encountered here wherein\u001b[39;00m\n\u001b[32m    199\u001b[39m         \u001b[38;5;66;03m# experiment creation fails\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\telemetry\\track.py:24\u001b[39m, in \u001b[36mrecord_usage_event.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(*args: P.args, **kwargs: P.kwargs) -> R:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_telemetry_disabled() \u001b[38;5;129;01mor\u001b[39;00m _is_telemetry_disabled_for_event(event):\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     success = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     27\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:298\u001b[39m, in \u001b[36mTrackingServiceClient.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[32m    285\u001b[39m \n\u001b[32m    286\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    295\u001b[39m \n\u001b[32m    296\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    297\u001b[39m _validate_experiment_artifact_location(artifact_location)\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mExperimentTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:254\u001b[39m, in \u001b[36mRestStore.create_experiment\u001b[39m\u001b[34m(self, name, artifact_location, tags)\u001b[39m\n\u001b[32m    250\u001b[39m tag_protos = [tag.to_proto() \u001b[38;5;28;01mfor\u001b[39;00m tag \u001b[38;5;129;01min\u001b[39;00m tags] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[32m    251\u001b[39m req_body = message_to_json(\n\u001b[32m    252\u001b[39m     CreateExperiment(name=name, artifact_location=artifact_location, tags=tag_protos)\n\u001b[32m    253\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m254\u001b[39m response_proto = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCreateExperiment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq_body\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response_proto.experiment_id\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\databricks_rest_store.py:100\u001b[39m, in \u001b[36mDatabricksTracingRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001b[39m\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_call_endpoint\u001b[39m(\n\u001b[32m     92\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m     93\u001b[39m     api,\n\u001b[32m   (...)\u001b[39m\u001b[32m     97\u001b[39m     response_proto=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m     98\u001b[39m ):\n\u001b[32m     99\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    101\u001b[39m \u001b[43m            \u001b[49m\u001b[43mapi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    103\u001b[39m \u001b[43m            \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m            \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m RestException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    108\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    109\u001b[39m             e.error_code == ErrorCode.Name(INVALID_PARAMETER_VALUE)\n\u001b[32m    110\u001b[39m             \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mCould not resolve a SQL warehouse ID\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m e.message\n\u001b[32m    111\u001b[39m         ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\store\\tracking\\rest_store.py:203\u001b[39m, in \u001b[36mRestStore._call_endpoint\u001b[39m\u001b[34m(self, api, json_body, endpoint, retry_timeout_seconds, response_proto)\u001b[39m\n\u001b[32m    201\u001b[39m     endpoint, method = \u001b[38;5;28mself\u001b[39m._METHOD_TO_INFO[api]\n\u001b[32m    202\u001b[39m response_proto = response_proto \u001b[38;5;129;01mor\u001b[39;00m api.Response()\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcall_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_host_creds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    205\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_timeout_seconds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    210\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:596\u001b[39m, in \u001b[36mcall_endpoint\u001b[39m\u001b[34m(host_creds, endpoint, method, json_body, response_proto, extra_headers, retry_timeout_seconds)\u001b[39m\n\u001b[32m    593\u001b[39m     call_kwargs[\u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m] = json_body\n\u001b[32m    594\u001b[39m     response = http_request(**call_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m596\u001b[39m response = \u001b[43mverify_rest_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    597\u001b[39m response_to_parse = response.text\n\u001b[32m    598\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Vivienne\\apps\\data_science_project\\Depression_Classification\\.venv\\Lib\\site-packages\\mlflow\\utils\\rest_utils.py:315\u001b[39m, in \u001b[36mverify_rest_response\u001b[39m\u001b[34m(response, endpoint)\u001b[39m\n\u001b[32m    313\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != \u001b[32m200\u001b[39m:\n\u001b[32m    314\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _can_parse_as_json_object(response.text):\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m RestException(json.loads(response.text))\n\u001b[32m    316\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    317\u001b[39m         base_msg = (\n\u001b[32m    318\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAPI request to endpoint \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    319\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfailed with error code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m != 200\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    320\u001b[39m         )\n",
      "\u001b[31mRestException\u001b[39m: RESOURCE_DOES_NOT_EXIST: Parent directory /Users/pipochatgpt@gmail.com does not exist."
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# Load .env and Log in to Databricks\n",
    "# ======================================\n",
    "\n",
    "# Cargar las variables del archivo .env\n",
    "load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/pipochatgpt@gmail.com/PEPE\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b74e27",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **Modelado** </font>\n",
    "Retomando un poco lo de entregas pasadas, este proyecto trabaja con un conjunto de datos cuyo objetivo es  **clasificar a estudiantes** en dos categorías: aquellos que presentan **síntomas de depresión** y **aquellos que no**. Debido a la naturaleza de los datos, estamos hablando de un problema de clasificación binaria, así que para esto, elegiremos modelos que se ajustan bien a este tipo de problemas:\n",
    "- Logistic Regression\n",
    "- SVC\n",
    "- XGBoost\n",
    "\n",
    "A continuación realizaremos la **optimización de hiperparámetros** y el **entrenamiento de tres modelos de clasificación binaria**. Para cada modelo:\n",
    "\n",
    "1. Se utiliza **Optuna** para explorar diferentes combinaciones de hiperparámetros y maximizar la `F1-score` (Esta es la métrica más balanceada ya que es un promedio). Cada combinación de parámetros se evalúa mediante una función objetivo (`objective`) que entrena el modelo, realiza predicciones sobre el conjunto de prueba y calcula métricas de rendimiento como `accuracy`, `precision`, `f1` y `recall`.\n",
    "\n",
    "2. Se emplea **MLflow** para hacer un seguimiento automático de los experimentos (`autolog`) y registrar los parámetros, métricas y modelos entrenados. \n",
    "\n",
    "3. Para Logistic Regression y SVC, se crean estudios de Optuna que prueban un número definido de configuraciones (`n_trials=3`) y se seleccionan los mejores parámetros encontrados. Para XGBoost, además se ajustan hiperparámetros como número de árboles, profundidad máxima, tasa de aprendizaje y gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134cff",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **Logistic Regression** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_lr(X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test.data, targets=Y_test, name='Test Data')\n",
    "\n",
    "    def objective_lr(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l2','l1','elasticnet'])\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'logistic_regression')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            lr_model = LogisticRegression(**params)\n",
    "            lr_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = lr_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                lr_model,\n",
    "                name='lr_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    lr_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Logisitc Regression (Optuna)', nested=True):\n",
    "        lr_study.optimize(objective_lr, n_trials=3)\n",
    "    \n",
    "    best_params_lr = lr_study.best_params\n",
    "\n",
    "    return best_params_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013af90",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **SVC** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1754a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_svc(X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test.data, targets=Y_test, name='Test Data')\n",
    "\n",
    "    def objective_svc(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'kernel': trial.suggest_categorical('kernel', ['sigmoid','poly','linear','rbf'])\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'svc')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            svc_model = SVC(**params)\n",
    "            svc_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = svc_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                svc_model,\n",
    "                name='svc_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    svc_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Support Vector Classifier (Optuna)', nested=True):\n",
    "        svc_study.optimize(objective_svc, n_trials=3)\n",
    "    \n",
    "    best_params_svc = svc_study.best_params\n",
    "\n",
    "    best_params_svc['random_state'] = 42\n",
    "\n",
    "    return best_params_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af8f19",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **XGBoost** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_xgboost(X_train, X_test, Y_train, Y_test):\n",
    "    # Habilitar autolog\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    # Crear datasets de entrenamiento y validación para MLflow\n",
    "    training_dataset = mlflow.data.from_numpy(X_train, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test, targets=Y_test, name='Test Data')\n",
    "\n",
    "    # Función objetivo para Optuna\n",
    "    def objective_xgb(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'Xgboost')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            xgb_model = XGBClassifier(**params)\n",
    "            xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.xgboost.log_model(\n",
    "                xgb_model,\n",
    "                artifact_path='xgboost_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    # Crear y ejecutar el estudio de Optuna\n",
    "    sampler = TPESampler(seed=42)\n",
    "    xgb_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='XGBoost (Optuna)', nested=True):\n",
    "        xgb_study.optimize(objective_xgb, n_trials=3)\n",
    "\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params_xgb = xgb_study.best_params\n",
    "    best_params_xgb['random_state'] = 42\n",
    "\n",
    "    return best_params_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13b787",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **MLFlow Registry** </font>\n",
    "En esta función se entrenan y evalúan los tres modelos seleccionados: Logistic Regression, SVC y XGBoost, utilizando los mejores hiperparámetros encontrados previamente. Para cada modelo se registran los parámetros, se calculan métricas de desempeño como accuracy, precision, recall y F1-score, y finalmente se almacenan los modelos en MLflow para su seguimiento y futura reutilización. La idea principal es automatizar el entrenamiento, evaluación y registro de los modelos de manera consistente y reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_models(X_train, Y_train, X_test, Y_test, best_params_lr, best_params_svc, best_params_xgb) -> None:\n",
    "    with mlflow.start_run(run_name='Logistic Regression Model'):\n",
    "        mlflow.log_params(best_params_lr)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'logistic_regression',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        lr = LogisticRegression(**best_params_lr)\n",
    "        lr.fit(X_train, Y_train)\n",
    "\n",
    "        y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "        acc_lr = accuracy_score(Y_test, y_pred_lr)\n",
    "        precision_lr = precision_score(Y_test, y_pred_lr)\n",
    "        f1_lr = f1_score(Y_test, y_pred_lr)\n",
    "        recall_lr = recall_score(Y_test, y_pred_lr)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_lr)\n",
    "        mlflow.log_metric('precision', precision_lr)\n",
    "        mlflow.log_metric('f1', f1_lr)\n",
    "        mlflow.log_metric('recall', recall_lr)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            lr,\n",
    "            name='model'\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name='SVC Model'):\n",
    "        mlflow.log_params(best_params_svc)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'svc',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        svc = SVC(**best_params_svc)\n",
    "        svc.fit(X_train, Y_train)\n",
    "\n",
    "        y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "        acc_svc = accuracy_score(Y_test, y_pred_svc)\n",
    "        precision_svc = precision_score(Y_test, y_pred_svc)\n",
    "        f1_svc = f1_score(Y_test, y_pred_svc)\n",
    "        recall_svc = recall_score(Y_test, y_pred_svc)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_svc)\n",
    "        mlflow.log_metric('precision', precision_svc)\n",
    "        mlflow.log_metric('f1', f1_svc)\n",
    "        mlflow.log_metric('recall', recall_svc)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            svc,\n",
    "            name='model'\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name='XGBoost Model'):\n",
    "        mlflow.log_params(best_params_xgb)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'Trees',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        xgb = XGBClassifier(**best_params_xgb)\n",
    "        xgb.fit(X_train, Y_train)\n",
    "        y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "        acc_xgb = accuracy_score(Y_test, y_pred_xgb)\n",
    "        precision_xgb = precision_score(Y_test, y_pred_xgb)\n",
    "        f1_xgb = f1_score(Y_test, y_pred_xgb)\n",
    "        recall_xgb = recall_score(Y_test, y_pred_xgb)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_xgb)\n",
    "        mlflow.log_metric('precision', precision_xgb)\n",
    "        mlflow.log_metric('f1', f1_xgb)\n",
    "        mlflow.log_metric('recall', recall_xgb)\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb,\n",
    "            name='model'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfc7df",
   "metadata": {},
   "source": [
    "Esta función se encarga de registrar automáticamente los dos mejores modelos de un experimento en el **Model Registry** de MLflow y asignarles los aliases `Champion` y `Challenger`. \n",
    "1. Primero busca todos los runs marcados como candidatos (`candidate=true`) y los ordena según la métrica F1. \n",
    "2. Luego selecciona los dos primeros: el de mayor F1 se registra como `Champion` y el segundo como `Challenger`. \n",
    "3. Cada modelo se registra en el model registry y se le asigna su alias correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_champion_challenger(experiment_id=\"0\", model_registry_name=\"workspace.\"):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        filter_string=\"tags.candidate = 'true'\",\n",
    "        order_by=[\"metrics.f1 DESC\"]\n",
    "    )\n",
    "\n",
    "    # Tomar los dos primeros runs \n",
    "    champion_run = runs[0]\n",
    "    challenger_run = runs[1] if len(runs) > 1 else None\n",
    "\n",
    "    def register(run, alias):\n",
    "        if run is None:\n",
    "            return\n",
    "        # Registrar modelo\n",
    "        result = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{run.info.run_id}/model\",\n",
    "            name=model_registry_name\n",
    "        )\n",
    "        # Asignar alias\n",
    "        client.set_registered_model_alias(\n",
    "            name=model_registry_name,\n",
    "            alias=alias,\n",
    "            version=result.version\n",
    "        )\n",
    "        print(f\"{alias} registrado: {run.data.tags['model_family']} con F1={run.data.metrics['f1']} (Run ID: {run.info.run_id})\")\n",
    "\n",
    "    # Registrar Champion y Challenger\n",
    "    register(champion_run, \"Champion\")\n",
    "    register(challenger_run, \"Challenger\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depression-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
