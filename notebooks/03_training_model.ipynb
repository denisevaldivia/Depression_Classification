{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5230de6c",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2\" width=\"240px\" height=\"180px\" />\n",
    "\n",
    "# <font color= #bbc28d> **Clasificaci√≥n de Depresi√≥n - Modelado** </font>\n",
    "#### <font color= #2E9AFE> `Proyecto de Ciencia de Datos`</font>\n",
    "- <Strong> Sof√≠a Maldonado, Diana Valdivia, Samantha S√°nchez & Vivienne Toledo </Strong>\n",
    "- <Strong> Fecha </Strong>: 11/11/2025.\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Image retrieved from: https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2/p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bbc203",
   "metadata": {},
   "source": [
    "# <font color= #bbc28d>**Datos y Data Readiness** </font>\n",
    "En esta etapa se sigui√≥ trabajando con la misma base de datos la cu√°l intenta clasificar a los j√≥venes estudiantes en dos categor√≠as: aquellos que presentan s√≠ntomas de depresi√≥n y aquellos que no, siendo esta columna nuestro objetivo. Aplicando diferentes transformaciones y limpiezas para preparar los datos antes del modelado. Las acciones principales fueron:\n",
    "\n",
    "#### <font color=#99c0c4>1. **Tratamiento de datos faltantes** </font>\n",
    "- Se detect√≥ que la columna Financial Stress conten√≠a 3 valores nulos.\n",
    "- Dado que era una cantidad peque√±a en comparaci√≥n con el total de registros, se decidi√≥ eliminar esas filas.\n",
    "\n",
    "#### <font color=#99c0c4>2. **Filtrado de datos categ√≥ricos** </font>\n",
    "- Se identificaron variables con categor√≠as poco representativas (con una o dos filas por valor), como City, Dietary Habits, Sleep Duration y Degree.\n",
    "- Se eliminaron registros aislados para reducir ruido y mejorar la representatividad de los datos.\n",
    "\n",
    "#### <font color=#99c0c4>3. **Ajuste del dataset al enfoque del proyecto** </font>\n",
    "- Se filtraron los registros de Age para conservar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3bd9446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Databricks Env\n",
    "import pathlib\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Feature Engineering\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Optimization\n",
    "import math\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "# MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7b739",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>‚Ä¢ **Credenciales & Set-up inicial** </font>\n",
    "Para poder trabajar con MLFlow es necesario ingresar con nuestros tokens de acceso y definir la base con la que estaremos trabajando, en nuestro caso ser√° con Databricks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2a36e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Load .env and Log in to Databricks\n",
    "# ======================================\n",
    "\n",
    "# Cargar las variables del archivo .env\n",
    "load_dotenv(override=True)  # Carga las variables del archivo .env\n",
    "EXPERIMENT_NAME = \"/Users/pipochatgpt@gmail.com/Depression_Class\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422e98f0",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>‚Ä¢ **Preprocesamiento** </font>\n",
    "\n",
    "Convertimos lo planteado en la libreta de limpieza de datos en una funci√≥n que limpie y preprocese los datos de la siguiente manera. \n",
    "\n",
    "### <font color= #7fb2b5>‚Ä¢ **Limpiado de Datos** </font>\n",
    "\n",
    "Consiste en una funci√≥n que toma el dataframe original y:\n",
    "\n",
    "- Elimina valores nulos\n",
    "- Filtra categor√≠as que tengan poca fuerza predictora\n",
    "- Codifica las variables categ√≥ricas binarias\n",
    "- Codifica las variables categ√≥ricas m√∫ltiples mediante codificaci√≥n ordinal\n",
    "- Realiza un train-test-val split (70-20-10) con una semilla fija\n",
    "\n",
    "Adem√°s, almacena los datos en carpetas dentro del almacenamiento local si el usuario lo indica.\n",
    "\n",
    "### <font color= #7fb2b5>‚Ä¢ **Preprocesamiento** </font>\n",
    "\n",
    "El preprocesamiento de datos retoma los valores obtenidos en la funci√≥n anterior y aplica una codificaci√≥n de tipo OneHot, adem√°s de una estandarizaci√≥n est√°ndar, con la librer√≠a de Scikit-Learn. Estos artefactos son almacenados en almacenamiento local y dentro de MLflow, si el usuario lo indica. \n",
    "\n",
    "El preprocesamiento se aplica antes de correr cada modelo y guarda los artefactos (OneHot y Standard Scaler) asociados a la run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "734d7a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/depression_dataset.csv\")\n",
    "\n",
    "def clean_data(df, save_data=False):\n",
    "    # 1. Eliminar valores nulos\n",
    "    df = df.dropna()\n",
    "\n",
    "\n",
    "    # 2. Filtrado de categor√≠as que otorgan poca informaci√≥n debido a su baja prevalencia\n",
    "    # City\n",
    "    ciudades = df['City'].value_counts()[df['City'].value_counts() < 450]\n",
    "    df = df[~df['City'].isin(ciudades.index)]\n",
    "    # Dietary Habits\n",
    "    df = df[df['Dietary Habits'] != 'Others']\n",
    "    # Sleep Duration\n",
    "    df = df[df['Sleep Duration'] != 'Others']\n",
    "    # Degree\n",
    "    df = df[df['Degree'] != 'Others']\n",
    "    # Age\n",
    "    df = df[df['Age'] <= 35]\n",
    "    # Academic Pressure\n",
    "    df = df[df['Academic Pressure'] > 0]\n",
    "    # Study Satisfaction\n",
    "    df = df[df['Study Satisfaction'] > 0]\n",
    "\n",
    "    # 3. Eliminar variables que no son buenas predictoras\n",
    "    df.drop(columns=['Work Pressure', 'Profession', 'Job Satisfaction', 'id'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    # 4. Mapear las variables categ√≥ricas binarias\n",
    "    gender = {'Male' : 0, 'Female' : 1}\n",
    "    general = {'Yes' : 1, 'No' : 0}\n",
    "    df['Gender'] = df['Gender'].map(gender)\n",
    "    df['Have you ever had suicidal thoughts ?'] = df['Have you ever had suicidal thoughts ?'].map(general)\n",
    "    df['Family History of Mental Illness'] = df['Family History of Mental Illness'].map(general)\n",
    "\n",
    "\n",
    "    # 5. Mapear las variables categ√≥ricas m√∫ltiples\n",
    "    degree = {\n",
    "    \"Class 12\": \"Secondary\",\n",
    "    \"B.Pharm\": \"Undergraduate\", \"BSc\": \"Undergraduate\", \"BA\": \"Undergraduate\", \"BCA\": \"Undergraduate\",\n",
    "    \"B.Ed\": \"Undergraduate\", \"LLB\": \"Undergraduate\", \"BE\": \"Undergraduate\", \"BHM\": \"Undergraduate\",\n",
    "    \"B.Com\": \"Undergraduate\", \"B.Arch\": \"Undergraduate\", \"B.Tech\": \"Undergraduate\", \"BBA\": \"Undergraduate\",\n",
    "    \"M.Tech\": \"Postgraduate\", \"M.Ed\": \"Postgraduate\", \"MSc\": \"Postgraduate\", \"M.Pharm\": \"Postgraduate\",\n",
    "    \"MCA\": \"Postgraduate\", \"MA\": \"Postgraduate\", \"MBA\": \"Postgraduate\", \"M.Com\": \"Postgraduate\", \"MHM\": \"Postgraduate\",\n",
    "    \"PhD\": \"Doctorate\", \"MD\": \"Doctorate\", \"MBBS\": \"Doctorate\", \"LLM\": \"Doctorate\", \"ME\": \"Postgraduate\"\n",
    "    }\n",
    "    orden_degree = {\"Secondary\": 0, \"Undergraduate\": 1, \"Postgraduate\": 2, \"Doctorate\": 3}\n",
    "    orden_alimentos = {'Healthy': 0, 'Unhealthy': 1, 'Moderate': 2}\n",
    "    orden_siesta = {'Less than 5 hours': 0, '5-6 hours': 1, '7-8 hours': 2,'More than 8 hours': 3}\n",
    "    # Aplicar el mapeo\n",
    "    df['Degree'] = df['Degree'].map(degree)\n",
    "    df['Degree'] = df['Degree'].map(orden_degree)\n",
    "    df['Dietary Habits'] = df['Dietary Habits'].map(orden_alimentos)\n",
    "    df['Sleep Duration'] = df['Sleep Duration'].map(orden_siesta)\n",
    "\n",
    "\n",
    "    # 6. Train-Test-Val Split (70-20-10)\n",
    "    X = df.drop(['Depression'], axis=1)\n",
    "    y = df['Depression']\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "    X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.66, random_state=42)\n",
    "\n",
    "    if save_data:\n",
    "        # Guardar las variables \n",
    "        X_train.to_csv(r'..\\data\\interim\\X_train.csv', index=False)\n",
    "        X_test.to_csv(r'..\\data\\interim\\X_test.csv', index=False)\n",
    "        X_val.to_csv(r'..\\data\\interim\\X_val.csv', index=False)\n",
    "        \n",
    "        y_train.to_csv(r'..\\data\\processed\\y_train.csv', index=False)\n",
    "        y_test.to_csv(r'..\\data\\processed\\y_test.csv', index=False)\n",
    "        y_val.to_csv(r'..\\data\\processed\\y_val.csv', index=False)\n",
    "    \n",
    "    # Convertir las variables dependientes en NumPy arrays\n",
    "    y_train = y_train.to_numpy().ravel()\n",
    "    y_test = y_test.to_numpy().ravel()\n",
    "    y_val = y_val.to_numpy().ravel()   \n",
    "\n",
    "    return X_train, X_test, X_val, y_train, y_test, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e76bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(X_train, X_test, X_val=None, save_data=False, save_artifacts=True):\n",
    "    # Codificar variables m√∫ltiples mediante One-Hot\n",
    "    encoder = OneHotEncoder(\n",
    "        drop='first',\n",
    "        handle_unknown='ignore',        # Evita error si aparece algo nuevo\n",
    "        sparse_output=False\n",
    "    )\n",
    "\n",
    "    # Entrenar el objeto con los datos del train\n",
    "    encoder.fit(X_train[['City']])\n",
    "    \n",
    "    # Aplicar One-Hot\n",
    "    X_train_city = encoder.transform(X_train[['City']])\n",
    "    X_test_city = encoder.transform(X_test[['City']])\n",
    "    X_val_city = encoder.transform(X_val[['City']]) if X_val is not None else None\n",
    "    \n",
    "    # Obtener los nombres del One-Hot\n",
    "    city_cols = encoder.get_feature_names_out(['City'])  # Nombres autom√°ticos de columnas\n",
    "    \n",
    "    # Crear un df con las columnas codificadas\n",
    "    X_train_city_df = pd.DataFrame(X_train_city, columns=city_cols, index=X_train.index)\n",
    "    X_test_city_df = pd.DataFrame(X_test_city, columns=city_cols, index=X_test.index)\n",
    "    X_val_city_df = pd.DataFrame(X_val_city, columns=city_cols, index=X_val.index) if X_val is not None else None\n",
    "    \n",
    "    # Eliminar la columna original en el dataset\n",
    "    X_train = X_train.drop(columns=['City'])\n",
    "    X_test = X_test.drop(columns=['City'])\n",
    "    X_val = X_val.drop(columns=['City']) if X_val is not None else None\n",
    "    \n",
    "    # Juntar las nuevas columnas con el dataset antiguo\n",
    "    X_train_final = pd.concat([X_train, X_train_city_df], axis=1)\n",
    "    X_test_final = pd.concat([X_test, X_test_city_df], axis=1)\n",
    "    X_val_final = pd.concat([X_val, X_val_city_df], axis=1) if X_val is not None else None\n",
    "\n",
    "    # Aplicar una estandarizaci√≥n a los datos\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_final)\n",
    "    X_test_scaled = scaler.transform(X_test_final)\n",
    "    X_val_scaled = scaler.transform(X_val_final) if X_val is not None else None\n",
    "\n",
    "    # Guardar los artefactos\n",
    "    if save_artifacts:\n",
    "        os.makedirs(\"artifacts/preprocessor\", exist_ok=True)\n",
    "\n",
    "        # Save encoder\n",
    "        with open('artifacts/preprocessor/encoder.pkl', 'wb') as f_out:\n",
    "            pickle.dump(encoder, f_out)\n",
    "        # Save scaler\n",
    "        with open('artifacts/preprocessor/scaler.pkl', 'wb') as f_out:\n",
    "            pickle.dump(scaler, f_out)\n",
    "\n",
    "        # Log artifacts to MLflow\n",
    "        mlflow.log_artifact(\"artifacts/preprocessor/encoder.pkl\", artifact_path=\"preprocessor\")\n",
    "        mlflow.log_artifact(\"artifacts/preprocessor/scaler.pkl\", artifact_path=\"preprocessor\")\n",
    "\n",
    "        print(\"Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\")\n",
    "\n",
    "    if save_data:\n",
    "        # Regresar los datos a dataframe y guardarlos\n",
    "        X_train_df = pd.DataFrame(X_train_scaled, columns=X_train_final.columns, index=X_train_final.index)\n",
    "        X_test_df = pd.DataFrame(X_test_scaled, columns=X_test_final.columns, index=X_test_final.index)\n",
    "        X_val_df = pd.DataFrame(X_val_scaled, columns=X_val_final.columns, index=X_val_final.index) if X_val is not None else None\n",
    "\n",
    "        X_train_df.to_csv(r'..\\data\\processed\\X_train.csv', index=False)\n",
    "        X_test_df.to_csv(r'..\\data\\processed\\X_test.csv', index=False)\n",
    "        X_val_df.to_csv(r'..\\data\\processed\\X_val.csv', index=False)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, X_val_scaled, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55425de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data and obtain the targets\n",
    "X_train, X_test, X_val, y_train, y_test, y_val = clean_data(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b74e27",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>‚Ä¢ **Modelado** </font>\n",
    "Retomando un poco lo de entregas pasadas, este proyecto trabaja con un conjunto de datos cuyo objetivo es  **clasificar a estudiantes** en dos categor√≠as: aquellos que presentan **s√≠ntomas de depresi√≥n** y **aquellos que no**. Debido a la naturaleza de los datos, estamos hablando de un problema de clasificaci√≥n binaria, as√≠ que para esto, elegiremos modelos que se ajustan bien a este tipo de problemas:\n",
    "- Logistic Regression\n",
    "- SVC\n",
    "- XGBoost\n",
    "\n",
    "A continuaci√≥n realizaremos la **optimizaci√≥n de hiperpar√°metros** y el **entrenamiento de tres modelos de clasificaci√≥n binaria**. Para cada modelo:\n",
    "\n",
    "1. Se utiliza **Optuna** para explorar diferentes combinaciones de hiperpar√°metros y maximizar la `F1-score` (Esta es la m√©trica m√°s balanceada ya que es un promedio). Cada combinaci√≥n de par√°metros se eval√∫a mediante una funci√≥n objetivo (`objective`) que entrena el modelo, realiza predicciones sobre el conjunto de prueba y calcula m√©tricas de rendimiento como `accuracy`, `precision`, `f1` y `recall`.\n",
    "\n",
    "2. Se emplea **MLflow** para hacer un seguimiento autom√°tico de los experimentos (`autolog`) y registrar los par√°metros, m√©tricas y modelos entrenados. \n",
    "\n",
    "3. Para Logistic Regression y SVC, se crean estudios de Optuna que prueban un n√∫mero definido de configuraciones (`n_trials=3`) y se seleccionan los mejores par√°metros encontrados. Para XGBoost, adem√°s se ajustan hiperpar√°metros como n√∫mero de √°rboles, profundidad m√°xima, tasa de aprendizaje y gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134cff",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>‚Ä¢ **Logistic Regression** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d04e156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_lr(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    # Start Optuna and MLflow\n",
    "    def objective_lr(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l2','l1','elasticnet']),\n",
    "            'solver': 'saga'\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Preprocess data and log artifacts\n",
    "            X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "            # Get MLflow ID to store the preprocessing artifacts\n",
    "            preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "            mlflow.set_tag('model_family', 'logistic_regression')\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "\n",
    "            lr_model = LogisticRegression(**params)\n",
    "            lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            # Get predictions and metrics\n",
    "            y_pred = lr_model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "\n",
    "            # Log metrics\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "            # Log the trained model\n",
    "            mlflow.sklearn.log_model(\n",
    "                lr_model,\n",
    "                name='lr_model',\n",
    "                input_example=X_test_scaled[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    lr_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Logistic Regression (Optuna)', nested=True):\n",
    "        lr_study.optimize(objective_lr, n_trials=3)\n",
    "    \n",
    "    best_params_lr = lr_study.best_params\n",
    "\n",
    "    return best_params_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013af90",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>‚Ä¢ **SVC** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b1754a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_svc(X_train, X_test, y_train, y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    def objective_svc(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'kernel': trial.suggest_categorical('kernel', ['sigmoid','poly','linear','rbf'])\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Preprocess data and log artifacts\n",
    "            X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "            # Get MLflow ID to store the preprocessing artifacts\n",
    "            preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "            mlflow.set_tag('model_family', 'svc')\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "\n",
    "            svc_model = SVC(**params)\n",
    "            svc_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            y_pred = svc_model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                svc_model,\n",
    "                name='svc_model',\n",
    "                input_example=X_test_scaled[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    svc_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Support Vector Classifier (Optuna)', nested=True):\n",
    "        svc_study.optimize(objective_svc, n_trials=3)\n",
    "    \n",
    "    best_params_svc = svc_study.best_params\n",
    "\n",
    "    best_params_svc['random_state'] = 42\n",
    "\n",
    "    return best_params_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af8f19",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>‚Ä¢ **XGBoost** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "50e996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_xgboost(X_train, X_test, y_train, y_test):\n",
    "    # Habilitar autolog\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    # Funci√≥n objetivo para Optuna\n",
    "    def objective_xgb(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            # Preprocess data and log artifacts\n",
    "            X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "            # Get MLflow ID to store the preprocessing artifacts\n",
    "            preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "\n",
    "            mlflow.set_tag('model_family', 'Xgboost')\n",
    "            mlflow.log_params(params)\n",
    "            mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "\n",
    "            xgb_model = XGBClassifier(**params)\n",
    "            xgb_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            y_pred = xgb_model.predict(X_test_scaled)\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            precision = precision_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred)\n",
    "            recall = recall_score(y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test_scaled, y_pred)\n",
    "\n",
    "            mlflow.xgboost.log_model(\n",
    "                xgb_model,\n",
    "                artifact_path='xgboost_model',\n",
    "                input_example=X_test_scaled[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    # Crear y ejecutar el estudio de Optuna\n",
    "    sampler = TPESampler(seed=42)\n",
    "    xgb_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='XGBoost (Optuna)', nested=True):\n",
    "        xgb_study.optimize(objective_xgb, n_trials=3)\n",
    "\n",
    "    # Obtener los mejores par√°metros\n",
    "    best_params_xgb = xgb_study.best_params\n",
    "    best_params_xgb['random_state'] = 42\n",
    "\n",
    "    return best_params_xgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb1d1e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:35:04,377] A new study created in memory with name: no-name-3a35aaf4-500c-474e-8461-3eacbfac4450\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:35:10 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/11 18:35:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d37562e7a6459e9dda85f5c2b4a997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:35:56 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-11-11 18:35:57,496] Trial 0 finished with value: 0.8603763987792472 and parameters: {'n_estimators': 87, 'max_depth': 10, 'learning_rate': 0.1205712628744377, 'gamma': 2.993292420985183}. Best is trial 0 with value: 0.8603763987792472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run painted-auk-836 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/b648e2e836ba4bc1bcbc008cdc8270fd\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:36:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/11 18:36:12 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6725886c408479588c038addd5588c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:36:25,804] Trial 1 finished with value: 0.8494370901892861 and parameters: {'n_estimators': 65, 'max_depth': 3, 'learning_rate': 0.012184186502221764, 'gamma': 4.330880728874676}. Best is trial 0 with value: 0.8603763987792472.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run charming-boar-629 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/c4d85184268247a2ae0a38d21891aeb4\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:36:28 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/11 18:36:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369625da6aae475fa0593c1c441e0024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:37:06,649] Trial 2 finished with value: 0.8604622111180512 and parameters: {'n_estimators': 110, 'max_depth': 8, 'learning_rate': 0.010725209743171996, 'gamma': 4.8495492608099715}. Best is trial 2 with value: 0.8604622111180512.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run kindly-bat-829 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/c0b96f28a7924c59968f8393991e792b\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "üèÉ View run XGBoost (Optuna) at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/5acd2f8926754e1fbc65ab363fa40782\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:37:08,481] A new study created in memory with name: no-name-fe9dff61-e9ca-4831-805b-cb396635019e\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52abbe69ba31493294eb477dd54e4bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:37:47 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run loud-chimp-509 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/d84d6b5e1d5a49dbb6ebbfd30b9b3460\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:38:20,471] Trial 0 finished with value: 0.8556892914753692 and parameters: {'kernel': 'poly'}. Best is trial 0 with value: 0.8556892914753692.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef26a17caa35496f874caac10a46c93b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:39:33 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run serious-cow-296 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/9cdb9de05ae647af881f59166fd3ea8d\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:39:38,643] Trial 1 finished with value: 0.8614564831261101 and parameters: {'kernel': 'rbf'}. Best is trial 1 with value: 0.8614564831261101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e27befa8914f5e836f32634cae66a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:40:42 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-11-11 18:40:47,235] Trial 2 finished with value: 0.8614564831261101 and parameters: {'kernel': 'rbf'}. Best is trial 1 with value: 0.8614564831261101.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run handsome-dog-971 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/b042ef11babe4afc892f4c90e58d82c2\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "üèÉ View run Support Vector Classifier (Optuna) at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/e36ea341d2ca42edb40efcf020993553\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:40:47,823] A new study created in memory with name: no-name-686b74d7-1448-4318-99e8-3b1d4e157d50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb47b4cb77b4138a21cfe0aef04cde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:41:13 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-11-11 18:41:15,475] Trial 0 finished with value: 0.8670476190476191 and parameters: {'penalty': 'l1'}. Best is trial 0 with value: 0.8670476190476191.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run rogue-fox-501 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/a330bbd695a648aca02a8da4197c39c5\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796eec37e54f4989999eca64e0f35abc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:41:43 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sneaky-shrew-96 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/a6f72242dc754b138a358a2ae576e1a0\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-11-11 18:41:45,148] Trial 1 finished with value: 0.8669037338074677 and parameters: {'penalty': 'l2'}. Best is trial 0 with value: 0.8670476190476191.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a3b16d993f4faea8a3d021a50686ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 18:42:11 INFO mlflow.models.model: Found the following environment variables used during model inference: [DATABRICKS_HOST, DATABRICKS_TOKEN]. Please check if you need to set them when deploying the model. To disable this message, set environment variable `MLFLOW_RECORD_ENV_VARS_IN_MODEL_LOGGING` to `false`.\n",
      "[I 2025-11-11 18:42:12,341] Trial 2 finished with value: 0.8670476190476191 and parameters: {'penalty': 'l1'}. Best is trial 0 with value: 0.8670476190476191.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run upbeat-wasp-948 at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/7db5888fbb324bdba8ecc2ea214b6431\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "üèÉ View run Logistic Regression (Optuna) at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/b128456551a64afd85197be6c640535e\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    }
   ],
   "source": [
    "best_params_xgb = hp_tuning_xgboost(X_train, X_test, y_train, y_test)\n",
    "best_params_svc = hp_tuning_svc(X_train, X_test, y_train, y_test)\n",
    "best_params_lr = hp_tuning_lr(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13b787",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>‚Ä¢ **MLFlow Registry** </font>\n",
    "En esta funci√≥n se entrenan y eval√∫an los tres modelos seleccionados: Logistic Regression, SVC y XGBoost, utilizando los mejores hiperpar√°metros encontrados previamente. Para cada modelo se registran los par√°metros, se calculan m√©tricas de desempe√±o como accuracy, precision, recall y F1-score, y finalmente se almacenan los modelos en MLflow para su seguimiento y futura reutilizaci√≥n. La idea principal es automatizar el entrenamiento, evaluaci√≥n y registro de los modelos de manera consistente y reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1325331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_models(X_train, y_train, X_test, y_test, best_params_lr, best_params_svc, best_params_xgb) -> None:\n",
    "    with mlflow.start_run(run_name=' Best Logistic Regression Model'):\n",
    "        # Preprocess data and log artifacts\n",
    "        X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "        # Get MLflow ID to store the preprocessing artifacts\n",
    "        preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "        mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "        mlflow.log_params(best_params_lr)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'logistic_regression',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        lr = LogisticRegression(**best_params_lr, solver='saga')\n",
    "        lr.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred_lr = lr.predict(X_test_scaled)\n",
    "\n",
    "        acc_lr = accuracy_score(y_test, y_pred_lr)\n",
    "        precision_lr = precision_score(y_test, y_pred_lr)\n",
    "        f1_lr = f1_score(y_test, y_pred_lr)\n",
    "        recall_lr = recall_score(y_test, y_pred_lr)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_lr)\n",
    "        mlflow.log_metric('precision', precision_lr)\n",
    "        mlflow.log_metric('f1', f1_lr)\n",
    "        mlflow.log_metric('recall', recall_lr)\n",
    "\n",
    "        signature = infer_signature(X_train_scaled, lr.predict(X_train_scaled))\n",
    "        mlflow.sklearn.log_model(\n",
    "            lr,\n",
    "            artifact_path='model',\n",
    "            signature=signature\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name=' Best SVC Model'):\n",
    "        # Preprocess data and log artifacts\n",
    "        X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "        # Get MLflow ID to store the preprocessing artifacts\n",
    "        preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "        mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "        mlflow.log_params(best_params_svc)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'svc',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        svc = SVC(**best_params_svc)\n",
    "        svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "        y_pred_svc = svc.predict(X_test_scaled)\n",
    "\n",
    "        acc_svc = accuracy_score(y_test, y_pred_svc)\n",
    "        precision_svc = precision_score(y_test, y_pred_svc)\n",
    "        f1_svc = f1_score(y_test, y_pred_svc)\n",
    "        recall_svc = recall_score(y_test, y_pred_svc)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_svc)\n",
    "        mlflow.log_metric('precision', precision_svc)\n",
    "        mlflow.log_metric('f1', f1_svc)\n",
    "        mlflow.log_metric('recall', recall_svc)\n",
    "\n",
    "        signature = infer_signature(X_train_scaled, svc.predict(X_train_scaled))\n",
    "        mlflow.sklearn.log_model(\n",
    "            svc,\n",
    "            artifact_path='model',\n",
    "            signature=signature\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name=' Best XGBoost Model'):\n",
    "        # Preprocess data and log artifacts\n",
    "        X_train_scaled, X_test_scaled, _, encoder, scaler = preprocessor(X_train, X_test, X_val=None, save_artifacts=True)\n",
    "\n",
    "        # Get MLflow ID to store the preprocessing artifacts\n",
    "        preprocessor_run_id = mlflow.active_run().info.run_id\n",
    "        mlflow.log_param('preprocessor_run_id', preprocessor_run_id)\n",
    "        mlflow.log_params(best_params_xgb)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'Trees',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        xgb = XGBClassifier(**best_params_xgb)\n",
    "        xgb.fit(X_train_scaled, y_train)\n",
    "        y_pred_xgb = xgb.predict(X_test_scaled)\n",
    "\n",
    "        acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "        precision_xgb = precision_score(y_test, y_pred_xgb)\n",
    "        f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "        recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_xgb)\n",
    "        mlflow.log_metric('precision', precision_xgb)\n",
    "        mlflow.log_metric('f1', f1_xgb)\n",
    "        mlflow.log_metric('recall', recall_xgb)\n",
    "\n",
    "        signature = infer_signature(X_train_scaled, xgb.predict(X_train_scaled))\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb,\n",
    "            artifact_path='model',\n",
    "            signature=signature\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bdbe7eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 19:10:20 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run  Best Logistic Regression Model at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/9c35dce01110455c896c628517b96a08\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 19:11:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run  Best SVC Model at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/3d2d721a3f554ceb8c4dfe5c49a0de75\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n",
      "Preprocessor artifacts (encoder & scaler) successfully logged to MLflow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 19:11:29 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/11/11 19:11:43 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run  Best XGBoost Model at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753/runs/b59d2b9b16b14247a07eb765a3ce5eb6\n",
      "üß™ View experiment at: https://dbc-c600c0c2-acad.cloud.databricks.com/ml/experiments/2425093441161753\n"
     ]
    }
   ],
   "source": [
    "train_best_models(X_train, y_train, X_test, y_test, best_params_lr, best_params_svc, best_params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfc7df",
   "metadata": {},
   "source": [
    "Esta funci√≥n se encarga de registrar autom√°ticamente los dos mejores modelos de un experimento en el **Model Registry** de MLflow y asignarles los aliases `Champion` y `Challenger`. \n",
    "1. Primero busca todos los runs marcados como candidatos (`candidate=true`) y los ordena seg√∫n la m√©trica F1. \n",
    "2. Luego selecciona los dos primeros: el de mayor F1 se registra como `Champion` y el segundo como `Challenger`. \n",
    "3. Cada modelo se registra en el model registry y se le asigna su alias correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72ff3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.DepressionClass' already exists. Creating a new version of this model...\n",
      "2025/11/11 19:12:09 WARNING mlflow.tracking._model_registry.fluent: Run with id 9c35dce01110455c896c628517b96a08 has no artifacts at artifact path 'model', registering model based on models:/m-7b722b8d073342f794c840fc6572b6be instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "971e6fa2884141d6a624afc6e3ab9230",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d32c1416b324fc787afe50039238e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '1' of model 'workspace.default.depressionclass'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Champion registrado: logistic_regression con F1=0.8670476190476191 (Run ID: 9c35dce01110455c896c628517b96a08)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'workspace.default.DepressionClass' already exists. Creating a new version of this model...\n",
      "2025/11/11 19:12:17 WARNING mlflow.tracking._model_registry.fluent: Run with id 3d2d721a3f554ceb8c4dfe5c49a0de75 has no artifacts at artifact path 'model', registering model based on models:/m-66cb9ba2e1d04c5d815173fe8d42e531 instead\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd5d694c9f44627ba1c5c4008e56277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba780ce47c449df86c3fe37b8c3e4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '2' of model 'workspace.default.depressionclass'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Challenger registrado: svc con F1=0.8614564831261101 (Run ID: 3d2d721a3f554ceb8c4dfe5c49a0de75)\n"
     ]
    }
   ],
   "source": [
    "# Setear la URI del Model Registry a legacy Workspace\n",
    "mlflow.set_registry_uri(\"databricks-uc\")\n",
    "\n",
    "def register_champion_challenger(exp=EXPERIMENT_NAME, model_registry_name=\"workspace.default.DepressionClass\"):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    # Buscar los runs candidatos ordenados por F1\n",
    "    runs = mlflow.search_runs(\n",
    "        experiment_names=[exp],\n",
    "        filter_string=\"tags.candidate = 'true'\",\n",
    "        order_by=[\"metrics.f1 DESC\"]\n",
    "    )\n",
    "\n",
    "    if runs.empty:\n",
    "        print(\"No candidate runs found.\")\n",
    "        return\n",
    "\n",
    "    # Tomar los dos mejores\n",
    "    champion = runs.iloc[0]\n",
    "    challenger = runs.iloc[1] if len(runs) > 1 else None\n",
    "\n",
    "    def register(run_row, alias):\n",
    "        if run_row is None:\n",
    "            return\n",
    "\n",
    "        run_id = run_row['run_id']\n",
    "        f1 = run_row['metrics.f1']\n",
    "        model_family = run_row['tags.model_family']\n",
    "\n",
    "        # Registrar modelo\n",
    "        result = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{run_id}/model\",\n",
    "            name=model_registry_name\n",
    "        )\n",
    "\n",
    "        # Asignar alias\n",
    "        client.set_registered_model_alias(\n",
    "            name=model_registry_name,\n",
    "            alias=alias,\n",
    "            version=result.version\n",
    "        )\n",
    "\n",
    "        print(f\"{alias} registrado: {model_family} con F1={f1} (Run ID: {run_id})\")\n",
    "\n",
    "    register(champion, \"Champion\")\n",
    "    register(challenger, \"Challenger\")\n",
    "\n",
    "register_champion_challenger()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab_modelado",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
