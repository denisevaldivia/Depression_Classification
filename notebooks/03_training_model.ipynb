{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5230de6c",
   "metadata": {},
   "source": [
    "___\n",
    "<img style=\"float: right; margin: 15px 15px 15px 15px;\" src=\"https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2\" width=\"240px\" height=\"180px\" />\n",
    "\n",
    "# <font color= #bbc28d> **Clasificación de Depresión - Modelado** </font>\n",
    "#### <font color= #2E9AFE> `Proyecto de Ciencia de Datos`</font>\n",
    "- <Strong> Sofía Maldonado, Diana Valdivia, Samantha Sánchez & Vivienne Toledo </Strong>\n",
    "- <Strong> Fecha </Strong>: 11/11/2025.\n",
    "\n",
    "___\n",
    "\n",
    "<p style=\"text-align:right;\"> Image retrieved from: https://img.freepik.com/free-vector/depression-concept-illustration_114360-3747.jpg?t=st=1657678284~exp=1657678884~hmac=b8b1d71ca0a8eb2e4ff5bf31d6a98624112f1a2254b0f39e92254ed12d7875b2/p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd9446a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "# Databricks Env\n",
    "import pathlib\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "# Feature Engineering\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# Optimization\n",
    "import math\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "# MLFlow\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "from mlflow import MlflowClient\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b7b739",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **Credenciales & Set-up inicial** </font>\n",
    "Para poder trabajar con MLFlow es necesario ingresar con nuestros tokens de acceso y definir la base con la que estaremos trabajando, en nuestro caso será con Databricks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a36e595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================================\n",
    "# Load .env and Log in to Databricks\n",
    "# ======================================\n",
    "\n",
    "# Cargar las variables del archivo .env\n",
    "load_dotenv(override=True)  \n",
    "EMAIL = os.getenv('EMAIL')\n",
    "PROJECT_NAME = os.getenv('PROJECT_NAME')\n",
    "EXPERIMENT_NAME = f\"/Users/{EMAIL}/{PROJECT_NAME}\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"databricks\")\n",
    "experiment = mlflow.set_experiment(experiment_name=EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b74e27",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **Modelado** </font>\n",
    "Retomando un poco lo de entregas pasadas, este proyecto trabaja con un conjunto de datos cuyo objetivo es  **clasificar a estudiantes** en dos categorías: aquellos que presentan **síntomas de depresión** y **aquellos que no**. Debido a la naturaleza de los datos, estamos hablando de un problema de clasificación binaria, así que para esto, elegiremos modelos que se ajustan bien a este tipo de problemas:\n",
    "- Logistic Regression\n",
    "- SVC\n",
    "- XGBoost\n",
    "\n",
    "A continuación realizaremos la **optimización de hiperparámetros** y el **entrenamiento de tres modelos de clasificación binaria**. Para cada modelo:\n",
    "\n",
    "1. Se utiliza **Optuna** para explorar diferentes combinaciones de hiperparámetros y maximizar la `F1-score` (Esta es la métrica más balanceada ya que es un promedio). Cada combinación de parámetros se evalúa mediante una función objetivo (`objective`) que entrena el modelo, realiza predicciones sobre el conjunto de prueba y calcula métricas de rendimiento como `accuracy`, `precision`, `f1` y `recall`.\n",
    "\n",
    "2. Se emplea **MLflow** para hacer un seguimiento automático de los experimentos (`autolog`) y registrar los parámetros, métricas y modelos entrenados. \n",
    "\n",
    "3. Para Logistic Regression y SVC, se crean estudios de Optuna que prueban un número definido de configuraciones (`n_trials=3`) y se seleccionan los mejores parámetros encontrados. Para XGBoost, además se ajustan hiperparámetros como número de árboles, profundidad máxima, tasa de aprendizaje y gamma."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e134cff",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **Logistic Regression** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04e156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_lr(X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test.data, targets=Y_test, name='Test Data')\n",
    "\n",
    "    def objective_lr(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'penalty': trial.suggest_categorical('penalty', ['l2','l1','elasticnet'])\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'logistic_regression')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            lr_model = LogisticRegression(**params)\n",
    "            lr_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = lr_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                lr_model,\n",
    "                name='lr_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    lr_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Logisitc Regression (Optuna)', nested=True):\n",
    "        lr_study.optimize(objective_lr, n_trials=3)\n",
    "    \n",
    "    best_params_lr = lr_study.best_params\n",
    "\n",
    "    return best_params_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1013af90",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **SVC** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1754a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_svc(X_train, X_test, Y_train, Y_test):\n",
    "\n",
    "    mlflow.sklearn.autolog()\n",
    "\n",
    "    training_dataset = mlflow.data.from_numpy(X_train.data, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test.data, targets=Y_test, name='Test Data')\n",
    "\n",
    "    def objective_svc(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'kernel': trial.suggest_categorical('kernel', ['sigmoid','poly','linear','rbf'])\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'svc')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            svc_model = SVC(**params)\n",
    "            svc_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = svc_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.sklearn.log_model(\n",
    "                svc_model,\n",
    "                name='svc_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "    \n",
    "    sampler = TPESampler(seed=42)\n",
    "    svc_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='Support Vector Classifier (Optuna)', nested=True):\n",
    "        svc_study.optimize(objective_svc, n_trials=3)\n",
    "    \n",
    "    best_params_svc = svc_study.best_params\n",
    "\n",
    "    best_params_svc['random_state'] = 42\n",
    "\n",
    "    return best_params_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2af8f19",
   "metadata": {},
   "source": [
    "### <font color= #7fb2b5>• **XGBoost** </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e996e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hp_tuning_xgboost(X_train, X_test, Y_train, Y_test):\n",
    "    # Habilitar autolog\n",
    "    mlflow.xgboost.autolog()\n",
    "\n",
    "    # Crear datasets de entrenamiento y validación para MLflow\n",
    "    training_dataset = mlflow.data.from_numpy(X_train, targets=Y_train, name='Train Data')\n",
    "    validation_dataset = mlflow.data.from_numpy(X_test, targets=Y_test, name='Test Data')\n",
    "\n",
    "    # Función objetivo para Optuna\n",
    "    def objective_xgb(trial: optuna.trial.Trial):\n",
    "        params = {\n",
    "            'n_estimators': trial.suggest_int('n_estimators', 50, 150),\n",
    "            'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'gamma': trial.suggest_float('gamma', 0, 5),\n",
    "            'eval_metric': 'logloss'\n",
    "        }\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.set_tag('model_family', 'Xgboost')\n",
    "            mlflow.log_params(params)\n",
    "\n",
    "            xgb_model = XGBClassifier(**params)\n",
    "            xgb_model.fit(X_train, Y_train)\n",
    "\n",
    "            y_pred = xgb_model.predict(X_test)\n",
    "            acc = accuracy_score(Y_test, y_pred)\n",
    "            precision = precision_score(Y_test, y_pred)\n",
    "            f1 = f1_score(Y_test, y_pred)\n",
    "            recall = recall_score(Y_test, y_pred)\n",
    "\n",
    "            mlflow.log_metric('acc', acc)\n",
    "            mlflow.log_metric('precision', precision)\n",
    "            mlflow.log_metric('f1', f1)\n",
    "            mlflow.log_metric('recall', recall)\n",
    "\n",
    "            signature = infer_signature(X_test, y_pred)\n",
    "\n",
    "            mlflow.xgboost.log_model(\n",
    "                xgb_model,\n",
    "                artifact_path='xgboost_model',\n",
    "                input_example=X_test[:5],\n",
    "                signature=signature\n",
    "            )\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    # Crear y ejecutar el estudio de Optuna\n",
    "    sampler = TPESampler(seed=42)\n",
    "    xgb_study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "\n",
    "    with mlflow.start_run(run_name='XGBoost (Optuna)', nested=True):\n",
    "        xgb_study.optimize(objective_xgb, n_trials=3)\n",
    "\n",
    "    # Obtener los mejores parámetros\n",
    "    best_params_xgb = xgb_study.best_params\n",
    "    best_params_xgb['random_state'] = 42\n",
    "\n",
    "    return best_params_xgb\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e13b787",
   "metadata": {},
   "source": [
    "## <font color= #bbc28d>• **MLFlow Registry** </font>\n",
    "En esta función se entrenan y evalúan los tres modelos seleccionados: Logistic Regression, SVC y XGBoost, utilizando los mejores hiperparámetros encontrados previamente. Para cada modelo se registran los parámetros, se calculan métricas de desempeño como accuracy, precision, recall y F1-score, y finalmente se almacenan los modelos en MLflow para su seguimiento y futura reutilización. La idea principal es automatizar el entrenamiento, evaluación y registro de los modelos de manera consistente y reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325331c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_best_models(X_train, Y_train, X_test, Y_test, best_params_lr, best_params_svc, best_params_xgb) -> None:\n",
    "    with mlflow.start_run(run_name='Logistic Regression Model'):\n",
    "        mlflow.log_params(best_params_lr)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'logistic_regression',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        lr = LogisticRegression(**best_params_lr)\n",
    "        lr.fit(X_train, Y_train)\n",
    "\n",
    "        y_pred_lr = lr.predict(X_test)\n",
    "\n",
    "        acc_lr = accuracy_score(Y_test, y_pred_lr)\n",
    "        precision_lr = precision_score(Y_test, y_pred_lr)\n",
    "        f1_lr = f1_score(Y_test, y_pred_lr)\n",
    "        recall_lr = recall_score(Y_test, y_pred_lr)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_lr)\n",
    "        mlflow.log_metric('precision', precision_lr)\n",
    "        mlflow.log_metric('f1', f1_lr)\n",
    "        mlflow.log_metric('recall', recall_lr)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            lr,\n",
    "            name='model'\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name='SVC Model'):\n",
    "        mlflow.log_params(best_params_svc)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'svc',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        svc = SVC(**best_params_svc)\n",
    "        svc.fit(X_train, Y_train)\n",
    "\n",
    "        y_pred_svc = svc.predict(X_test)\n",
    "\n",
    "        acc_svc = accuracy_score(Y_test, y_pred_svc)\n",
    "        precision_svc = precision_score(Y_test, y_pred_svc)\n",
    "        f1_svc = f1_score(Y_test, y_pred_svc)\n",
    "        recall_svc = recall_score(Y_test, y_pred_svc)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_svc)\n",
    "        mlflow.log_metric('precision', precision_svc)\n",
    "        mlflow.log_metric('f1', f1_svc)\n",
    "        mlflow.log_metric('recall', recall_svc)\n",
    "\n",
    "        mlflow.sklearn.log_model(\n",
    "            svc,\n",
    "            name='model'\n",
    "        )\n",
    "    \n",
    "    with mlflow.start_run(run_name='XGBoost Model'):\n",
    "        mlflow.log_params(best_params_xgb)\n",
    "        mlflow.set_tags({\n",
    "            'project': 'Depression Prediction Project',\n",
    "            'optimizer_engine': 'Optuna',\n",
    "            'model_family': 'Trees',\n",
    "            'feature_set_version': 1,\n",
    "            'candidate': 'true'\n",
    "        })\n",
    "\n",
    "        xgb = XGBClassifier(**best_params_xgb)\n",
    "        xgb.fit(X_train, Y_train)\n",
    "        y_pred_xgb = xgb.predict(X_test)\n",
    "\n",
    "        acc_xgb = accuracy_score(Y_test, y_pred_xgb)\n",
    "        precision_xgb = precision_score(Y_test, y_pred_xgb)\n",
    "        f1_xgb = f1_score(Y_test, y_pred_xgb)\n",
    "        recall_xgb = recall_score(Y_test, y_pred_xgb)\n",
    "\n",
    "        mlflow.log_metric('acc', acc_xgb)\n",
    "        mlflow.log_metric('precision', precision_xgb)\n",
    "        mlflow.log_metric('f1', f1_xgb)\n",
    "        mlflow.log_metric('recall', recall_xgb)\n",
    "\n",
    "        mlflow.xgboost.log_model(\n",
    "            xgb,\n",
    "            name='model'\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37dfc7df",
   "metadata": {},
   "source": [
    "Esta función se encarga de registrar automáticamente los dos mejores modelos de un experimento en el **Model Registry** de MLflow y asignarles los aliases `Champion` y `Challenger`. \n",
    "1. Primero busca todos los runs marcados como candidatos (`candidate=true`) y los ordena según la métrica F1. \n",
    "2. Luego selecciona los dos primeros: el de mayor F1 se registra como `Champion` y el segundo como `Challenger`. \n",
    "3. Cada modelo se registra en el model registry y se le asigna su alias correspondiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a72ff3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_champion_challenger(experiment_id=\"0\", model_registry_name=\"workspace.\"):\n",
    "    client = MlflowClient()\n",
    "\n",
    "    runs = client.search_runs(\n",
    "        experiment_ids=[experiment_id],\n",
    "        filter_string=\"tags.candidate = 'true'\",\n",
    "        order_by=[\"metrics.f1 DESC\"]\n",
    "    )\n",
    "\n",
    "    # Tomar los dos primeros runs \n",
    "    champion_run = runs[0]\n",
    "    challenger_run = runs[1] if len(runs) > 1 else None\n",
    "\n",
    "    def register(run, alias):\n",
    "        if run is None:\n",
    "            return\n",
    "        # Registrar modelo\n",
    "        result = mlflow.register_model(\n",
    "            model_uri=f\"runs:/{run.info.run_id}/model\",\n",
    "            name=model_registry_name\n",
    "        )\n",
    "        # Asignar alias\n",
    "        client.set_registered_model_alias(\n",
    "            name=model_registry_name,\n",
    "            alias=alias,\n",
    "            version=result.version\n",
    "        )\n",
    "        print(f\"{alias} registrado: {run.data.tags['model_family']} con F1={run.data.metrics['f1']} (Run ID: {run.info.run_id})\")\n",
    "\n",
    "    # Registrar Champion y Challenger\n",
    "    register(champion_run, \"Champion\")\n",
    "    register(challenger_run, \"Challenger\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "depression-classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
